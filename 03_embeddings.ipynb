{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc269fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\rag-from-scratch\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Callable, Any\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6089c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document.py\n",
    "class Document:\n",
    "    def __init__(self, pageContent: str, metadata: dict, id: str):\n",
    "        self.pageContent = pageContent  # raw text from pdf\n",
    "        self.metadata: dict = metadata  # pdf metadata (author, date ...)\n",
    "        self.id = id  # pdf id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937866fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "THIS = Path.cwd()\n",
    "STORAGE_DIR = THIS.joinpath(\"/embedding\")\n",
    "MODEL_PATH = THIS.joinpath(\"/models\", \"Q4_K_M.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7b6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingAdapter:\n",
    "    \"\"\"Abstract embedding adapter\"\"\"\n",
    "\n",
    "    def embed_texts(self, text: List[str]) -> List[np.ndarray]:\n",
    "        raise NotImplementedError(\"Must be implemented by sub-class\")\n",
    "    \n",
    "class DummyAdapter(EmbeddingAdapter):\n",
    "    \"\"\"Deterministic simulated embeddings for testing\"\"\"\n",
    "    def __init__(self, dim: int = 384):\n",
    "        self.dim = dim\n",
    "\n",
    "    def embed_texts(self, texts: List[str]) -> List[np.ndarray]:\n",
    "        out = []\n",
    "        for text in texts:\n",
    "\n",
    "            h = hashlib.sha256(text.encode(\"utf-8\")).hexdigest()[:16]\n",
    "            seed = int(h, 16) % (2**31 - 1)\n",
    "            rng = np.random.RandomState(seed=seed)\n",
    "            vec = rng.normal(size=(self.dim,))\n",
    "            norm = np.linalg.norm(vec)\n",
    "            if norm > 0:\n",
    "                vec = vec / norm\n",
    "            out.append(vec.astype(float))\n",
    "        return out\n",
    "    \n",
    "    class SentenceTransformerAdapter(EmbeddingAdapter):\n",
    "        \"\"\"Adapter for using sentence transformer\"\"\"\n",
    "        def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "            self.model = SentenceTransformer(model_name)\n",
    "\n",
    "        def embed_texts(self, texts: List[str]) -> List[np.ndarray]:\n",
    "            arr = self.model.encode(texts, show_progress_bar=False)\n",
    "            if isinstance(arr, np.ndarray) and arr.ndim == 2:\n",
    "                return [arr[i].astype(float) for i in range(arr.shape[0])]\n",
    "            return [np.asarray(a, dtype=float) for a in arr]\n",
    "        \n",
    "    class LlamaCppAdapter(EmbeddingAdapter):\n",
    "        \"\"\"Adapter for using Llama_cpp_python\"\"\"\n",
    "\n",
    "        def __init__(self, model_name: str = \"Q4_K_M\", model_path = MODEL_PATH):\n",
    "            NotImplementedError\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c872783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def stable_id_from_text(text: str, prefix: str = \"doc\"):\n",
    "    pass\n",
    "\n",
    "def chunked(iterable: List[Any], batch_size: int):\n",
    "    for i in range(0, len(iterable), batch_size):\n",
    "        yield iterable[i: i + batch_size]\n",
    "\n",
    "def ensure_storage_dir():\n",
    "    STORAGE_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f60e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the embedding model\n",
    "\n",
    "def initializeEmbeddingModel(use_dummy: bool = True, **kwargs) -> EmbeddingAdapter:\n",
    "    if use_dummy:\n",
    "        return DummyAdapter(**kwargs)\n",
    "    else:\n",
    "        return NotImplementedError(\"No Adapters available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "740425d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(adapter: EmbeddingAdapter, documents: List[Document],\n",
    "                        batch_size: int = 8,\n",
    "                        on_progress: Optional[Callable[[int, int], None]] = None) -> List[Dict[str, Any]]:\n",
    "    \n",
    "    ensure_storage_dir()\n",
    "    records: List[Dict[str, Any]] = []\n",
    "    processed = 0\n",
    "    total = len(documents)\n",
    "\n",
    "    for batch in chunked(documents, batch_size):\n",
    "        texts = [doc.pageContent for doc in batch]\n",
    "        vectors = adapter.embed_texts(texts)\n",
    "\n",
    "        for doc, vec in zip(batch, vectors):\n",
    "            rec_id = doc.id if getattr(doc, \"id\", None) else stable_id_from_text(doc.pageContent)\n",
    "            embedding_list = list(map(float, np.asarray(vec).tolist()))\n",
    "            record = {\n",
    "                \"id\": rec_id,\n",
    "                \"content\": doc.pageContent,\n",
    "                \"metadata\": doc.metadata,\n",
    "                \"embedding\": embedding_list,\n",
    "                \"timestamp\": int(time.time() * 1000)\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "            processed += 1\n",
    "            \n",
    "            if on_progress:\n",
    "                on_progress(processed, total)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "095477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings_json(embeddings: List[Dict[str, Any]], filename: str = \"embeddings_json\") -> Dict[str, Any]:\n",
    "    \"\"\"Save embeddings to STORAGE_DIR/embeddings_json\"\"\"\n",
    "\n",
    "    ensure_storage_dir()\n",
    "    filepath = STORAGE_DIR.joinpath(filename)\n",
    "\n",
    "    data = {\n",
    "        \"version\": \"1.0\",\n",
    "        \"model\": \"dummy\" if isinstance(embeddings, list) and len(embeddings) > 0 else \"unknown\",\n",
    "        \"dimensions\": len(embeddings[0][\"embedding\"]) if embeddings else None,\n",
    "        \"count\": len(embeddings),\n",
    "        \"created\": datetime.now(time.time()) + \"Z\",\n",
    "        \"embeddings\": embeddings\n",
    "    }\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "    size = filepath.stat().st_size\n",
    "    return {\"filepath\": str(filepath), \"size\": size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_json(filename: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load embeddings JSON and return the list at data[\"embeddings]\"\"\"\n",
    "    filepath"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
