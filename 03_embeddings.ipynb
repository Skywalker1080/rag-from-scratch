{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcc269fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Callable, Any\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6089c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document.py\n",
    "class Document:\n",
    "    def __init__(self, pageContent: str, metadata: dict, id: str):\n",
    "        self.pageContent = pageContent  # raw text from pdf\n",
    "        self.metadata: dict = metadata  # pdf metadata (author, date ...)\n",
    "        self.id = id  # pdf id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "937866fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "THIS = Path.cwd()\n",
    "STORAGE_DIR = THIS.joinpath(\"embedding\")\n",
    "MODEL_PATH = THIS.joinpath(\"/models\", \"Q4_K_M.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba7b6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingAdapter:\n",
    "    \"\"\"Abstract embedding adapter\"\"\"\n",
    "\n",
    "    def embed_texts(self, text: List[str]) -> List[np.ndarray]:\n",
    "        raise NotImplementedError(\"Must be implemented by sub-class\")\n",
    "    \n",
    "class DummyAdapter(EmbeddingAdapter):\n",
    "    \"\"\"Deterministic simulated embeddings for testing\"\"\"\n",
    "    def __init__(self, dim: int = 384):\n",
    "        self.dim = dim\n",
    "\n",
    "    def embed_texts(self, texts: List[str]) -> List[np.ndarray]:\n",
    "        out = []\n",
    "        for text in texts:\n",
    "\n",
    "            h = hashlib.sha256(text.encode(\"utf-8\")).hexdigest()[:16]\n",
    "            seed = int(h, 16) % (2**31 - 1)\n",
    "            rng = np.random.RandomState(seed=seed)\n",
    "            vec = rng.normal(size=(self.dim,))\n",
    "            norm = np.linalg.norm(vec)\n",
    "            if norm > 0:\n",
    "                vec = vec / norm\n",
    "            out.append(vec.astype(float))\n",
    "        return out\n",
    "    \n",
    "class SentenceTransformerAdapter(EmbeddingAdapter):\n",
    "    \"\"\"Adapter for using sentence transformer\"\"\"\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        print(f\"Loading SentenceTransformer model: {model_name}\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        print(f\"✓ Model loaded successfully\")\n",
    "\n",
    "    def embed_texts(self, texts: List[str]) -> List[np.ndarray]:\n",
    "        arr = self.model.encode(texts, show_progress_bar=False)\n",
    "        if isinstance(arr, np.ndarray) and arr.ndim == 2:\n",
    "            return [arr[i].astype(float) for i in range(arr.shape[0])]\n",
    "        return [np.asarray(a, dtype=float) for a in arr]\n",
    "    \n",
    "class LlamaCppAdapter(EmbeddingAdapter):\n",
    "    \"\"\"Adapter for using Llama_cpp_python\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"Q4_K_M\", model_path = MODEL_PATH):\n",
    "        NotImplementedError\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c872783a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def stable_id_from_text(text: str, prefix: str = \"doc\"):\n",
    "    h = hashlib.sha256(text.encode(\"utf-8\")).hexdigest()\n",
    "    return f\"{prefix}_{h[:16]}\"\n",
    "\n",
    "def chunked(iterable: List[Any], batch_size: int):\n",
    "    for i in range(0, len(iterable), batch_size):\n",
    "        yield iterable[i: i + batch_size]\n",
    "\n",
    "def ensure_storage_dir():\n",
    "    STORAGE_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f60e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the embedding model\n",
    "\n",
    "def initializeEmbeddingModel(use_dummy: bool = True, **kwargs) -> EmbeddingAdapter:\n",
    "    if use_dummy:\n",
    "        return DummyAdapter(**kwargs)\n",
    "    else:\n",
    "        return SentenceTransformerAdapter(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "740425d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(adapter: EmbeddingAdapter, documents: List[Document],\n",
    "                        batch_size: int = 8,\n",
    "                        on_progress: Optional[Callable[[int, int], None]] = None) -> List[Dict[str, Any]]:\n",
    "    \n",
    "    ensure_storage_dir()\n",
    "    records: List[Dict[str, Any]] = []\n",
    "    processed = 0\n",
    "    total = len(documents)\n",
    "\n",
    "    for batch in chunked(documents, batch_size):\n",
    "        texts = [doc.pageContent for doc in batch]\n",
    "        vectors = adapter.embed_texts(texts)\n",
    "\n",
    "        for doc, vec in zip(batch, vectors):\n",
    "            rec_id = doc.id if getattr(doc, \"id\", None) else stable_id_from_text(doc.pageContent)\n",
    "            embedding_list = list(map(float, np.asarray(vec).tolist()))\n",
    "            record = {\n",
    "                \"id\": rec_id,\n",
    "                \"content\": doc.pageContent,\n",
    "                \"metadata\": doc.metadata,\n",
    "                \"embedding\": embedding_list,\n",
    "                \"timestamp\": int(time.time() * 1000)\n",
    "            }\n",
    "            records.append(record)\n",
    "\n",
    "            processed += 1\n",
    "            \n",
    "            if on_progress:\n",
    "                on_progress(processed, total)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "095477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings_json(embeddings: List[Dict[str, Any]], filename: str = \"embeddings_json\") -> Dict[str, Any]:\n",
    "    \"\"\"Save embeddings to STORAGE_DIR/embeddings_json\"\"\"\n",
    "\n",
    "    ensure_storage_dir()\n",
    "    filepath = STORAGE_DIR.joinpath(filename)\n",
    "\n",
    "    data = {\n",
    "        \"version\": \"1.0\",\n",
    "        \"model\": \"sentence-transformer\" if isinstance(embeddings, list) and len(embeddings) > 0 else \"unknown\",\n",
    "        \"dimensions\": len(embeddings[0][\"embedding\"]) if embeddings and len(embeddings) > 0 else None,\n",
    "        \"count\": len(embeddings),\n",
    "        \"created\": datetime.now().isoformat() + \"Z\",\n",
    "        \"embeddings\": embeddings\n",
    "    }\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "    size = filepath.stat().st_size\n",
    "    return {\"filepath\": str(filepath), \"size\": size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b0d5293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_json(filename: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load embeddings JSON and return the list at data[\"embeddings]\"\"\"\n",
    "    filepath = STORAGE_DIR.joinpath(filename)\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return data[\"embeddings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67dae5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing_embeddings(filename: str) -> Dict[str, Dict[str, Any]]:\n",
    "    try:\n",
    "        embeddings = load_embeddings_json(filename)\n",
    "        emb_map = {item[\"id\"]: item for item in embeddings}\n",
    "        return emb_map\n",
    "    except FileNotFoundError:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4ae93781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def incremental_embedding(\n",
    "        adapter: EmbeddingAdapter,\n",
    "        new_documents: List[Document],\n",
    "        existing_filename: str,\n",
    "        batch_size: int = 8\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load exisiting embeddings by (filename), embed only those file whose id is missing\"\"\"\n",
    "    existing_map = load_existing_embeddings(existing_filename)\n",
    "\n",
    "    docs_to_embed: List[Document] = []\n",
    "    for doc in new_documents:\n",
    "        candidate_id = doc.id if getattr(doc, \"id\", None) else doc.pageContent[:50]\n",
    "        if candidate_id not in existing_map:\n",
    "            docs_to_embed.append(Document(doc.pageContent, doc.metadata, doc.id))\n",
    "\n",
    "    print(f\"Existing embeddings: {len(existing_map)}\")\n",
    "    print(f\"New documents to embed: {len(docs_to_embed)}\")\n",
    "    print(f\"Skipped (already embedded): {len(new_documents) - len(docs_to_embed)}\")\n",
    "\n",
    "    if len(docs_to_embed) == 0:\n",
    "        print(\"All documents already embedded!\")\n",
    "        # return array of existing records\n",
    "        return list(existing_map.values())\n",
    "    \n",
    "    new_embeddings = generate_embeddings(\n",
    "        adapter, docs_to_embed, batch_size, on_progress=lambda cur, tot: print(f\"\\rEmbedding: {cur}/{tot}\", end=\"\", flush=True)\n",
    "    )\n",
    "    print()\n",
    "\n",
    "    merged = list(existing_map.values()) + new_embeddings\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f07d3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_documents(count: int = 50) -> List[Document]:\n",
    "    topics = [\n",
    "        \"artificial intelligence\", \"machine learning\", \"natural language processing\",\n",
    "        \"computer vision\", \"data science\", \"cloud computing\", \"cybersecurity\",\n",
    "        \"blockchain\", \"quantum computing\", \"robotics\", \"virtual reality\"\n",
    "    ]\n",
    "    templates = [\n",
    "        lambda topic: f\"Recent advances in {topic} have revolutionized the technology industry.\",\n",
    "        lambda topic: f\"Understanding {topic} is crucial for modern software development.\",\n",
    "        lambda topic: f\"The future of {topic} looks promising with new innovations.\",\n",
    "        lambda topic: f\"Companies are investing heavily in {topic} research and development.\",\n",
    "        lambda topic: f\"{topic} applications are transforming how we work and live.\"\n",
    "    ]\n",
    "\n",
    "    docs: List[Document] = []\n",
    "    for i in range(count):\n",
    "        topic = topics[i % len(topics)]\n",
    "        template = templates[i % len(templates)]\n",
    "        text = template(topic)\n",
    "        docs.append(Document(text, {\"id\": f\"doc_{i}\", \"topic\": topic, \"source\": \"sample_generator\", \"index\": i}, id=f\"doc_{i}\"))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36fdb806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Example flows: example_1 .. example_6 (similar to JS, but adapted)\n",
    "# - These are provided so you can run them later for testing.\n",
    "# - They call the helper functions above.\n",
    "# ---------------------------------------------------------------------\n",
    "def example_1(adapter: EmbeddingAdapter):\n",
    "    \"\"\"Batch Embedding Generation\"\"\"\n",
    "    print(\"Loading embedding model (adapter)...\")\n",
    "    docs = create_sample_documents(100)\n",
    "    print(f\"Total Documents: {len(docs)}\")\n",
    "    print(\"\\nGenerating embeddings:\")\n",
    "    start = time.time()\n",
    "    embeddings = generate_embeddings(adapter, docs, batch_size=16, on_progress=lambda c, t: print(f\"\\rProgress: {c}/{t}\", end=\"\", flush=True))\n",
    "    duration = time.time() - start\n",
    "    print(f\"\\n✓ Completed in {duration:.2f}s\")\n",
    "    avg_ms = (duration / len(docs)) * 1000\n",
    "    print(f\"Total Embeddings: {len(embeddings)}, Average Time: {avg_ms:.2f}ms per document, Throughput: {len(docs)/duration:.2f} docs/sec\")\n",
    "    return embeddings\n",
    "\n",
    "def example_2(adapter: EmbeddingAdapter):\n",
    "    \"\"\"Save and Load Embeddings\"\"\"\n",
    "    docs = create_sample_documents(50)\n",
    "    print(\"\\nPhase 1: Generate and Save\")\n",
    "    start = time.time()\n",
    "    embeddings = generate_embeddings(adapter, docs, batch_size=8)\n",
    "    gen_time = (time.time() - start)\n",
    "    save_info = save_embeddings_json(embeddings, \"embeddings.json\")\n",
    "    print(f\"✓ Generated {len(embeddings)} embeddings in {gen_time:.2f}s\")\n",
    "    print(f\"✓ Saved to {save_info['filepath']} (size: {save_info['size'] / 1024 / 1024:.2f} MB)\")\n",
    "\n",
    "    print(\"\\nPhase 2: Load from Disk\")\n",
    "    start_load = time.time()\n",
    "    loaded = load_embeddings_json(\"embeddings.json\")\n",
    "    load_time_ms = (time.time() - start_load) * 1000\n",
    "    print(f\"✓ Loaded {len(loaded)} embeddings in {load_time_ms:.0f}ms\")\n",
    "    return loaded\n",
    "\n",
    "def example_3(adapter: EmbeddingAdapter):\n",
    "    \"\"\"Incremental Updates\"\"\"\n",
    "    print(\"\\nPhase 1: Initial Batch\")\n",
    "    initial_docs = create_sample_documents(30)\n",
    "    initial_embeddings = generate_embeddings(adapter, initial_docs, batch_size=8)\n",
    "    save_embeddings_json(initial_embeddings, \"incremental.json\")\n",
    "    print(f\"✓ Generated and saved {len(initial_embeddings)} embeddings\")\n",
    "\n",
    "    print(\"\\nPhase 2: Add New Documents\")\n",
    "    new_docs = [Document(d.pageContent, d.metadata, id=f\"doc_{30+i}\") for i, d in enumerate(create_sample_documents(20))]\n",
    "    duplicate_docs = create_sample_documents(5)  # duplicates: doc_0..doc_4\n",
    "    all_docs = new_docs + duplicate_docs\n",
    "\n",
    "    print(f\"\\nAttempting to process {len(all_docs)} documents:\")\n",
    "    print(f\"  - {len(new_docs)} new documents\")\n",
    "    print(f\"  - {len(duplicate_docs)} duplicates (should skip)\")\n",
    "\n",
    "    start_update = time.time()\n",
    "    updated = incremental_embedding(adapter, all_docs, \"incremental.json\", batch_size=8)\n",
    "    update_time = time.time() - start_update\n",
    "\n",
    "    save_embeddings_json(updated, \"incremental.json\")\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\" Total Embeddings: {len(updated)}\")\n",
    "    print(f\" Update Time: {update_time:.2f}s\")\n",
    "    print(f\" New Embeddings: {len(new_docs)}\")\n",
    "    print(f\" Skipped: {len(duplicate_docs)}\")\n",
    "    return updated\n",
    "\n",
    "def example_4(adapter: EmbeddingAdapter):\n",
    "    \"\"\"Storage Format Comparison (JSON only implemented here)\"\"\"\n",
    "    docs = create_sample_documents(100)\n",
    "    print(\"\\nGenerating embeddings for format comparison...\")\n",
    "    embeddings = generate_embeddings(adapter, docs, batch_size=16)\n",
    "    print(\"\\nSaving formats:\")\n",
    "    json_info = save_embeddings_json(embeddings, \"comparison.json\")\n",
    "    print(f\"✓ JSON: {json_info['size'] / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "    print(\"\\nLoad Time Comparison:\")\n",
    "    start_json = time.time()\n",
    "    _ = load_embeddings_json(\"comparison.json\")\n",
    "    json_load_time_ms = (time.time() - start_json) * 1000\n",
    "    print(f\"JSON: {json_load_time_ms:.0f}ms\")\n",
    "    return json_info\n",
    "\n",
    "\n",
    "def example_5(adapter: EmbeddingAdapter):\n",
    "    \"\"\"Preparing for Vector Stores (formatting)\"\"\"\n",
    "    print(\"\\nSimulating real document processing (chunks)...\")\n",
    "    mock_chunks = [\n",
    "        Document(\"Introduction to machine learning and its applications in modern technology.\", {\"source\": \"ml_guide.pdf\", \"page\": 1, \"chunk\": 0, \"totalChunks\": 3}, id=\"pdf_1_chunk_0\"),\n",
    "        Document(\"Supervised learning algorithms include decision trees and neural networks.\", {\"source\": \"ml_guide.pdf\", \"page\": 1, \"chunk\": 1, \"totalChunks\": 3}, id=\"pdf_1_chunk_1\"),\n",
    "        Document(\"Deep learning has revolutionized computer vision and natural language processing.\", {\"source\": \"ml_guide.pdf\", \"page\": 2, \"chunk\": 2, \"totalChunks\": 3}, id=\"pdf_1_chunk_2\")\n",
    "    ]\n",
    "    embeddings = generate_embeddings(adapter, mock_chunks, batch_size=3)\n",
    "    # vector store format\n",
    "    vector_store_format = [\n",
    "        {\n",
    "            \"id\": e[\"id\"],\n",
    "            \"vector\": e[\"embedding\"],\n",
    "            \"metadata\": {\n",
    "                \"content\": e[\"content\"],\n",
    "                \"source\": e[\"metadata\"].get(\"source\"),\n",
    "                \"page\": e[\"metadata\"].get(\"page\"),\n",
    "                \"chunk\": e[\"metadata\"].get(\"chunk\"),\n",
    "                \"timestamp\": e[\"timestamp\"]\n",
    "            }\n",
    "        }\n",
    "        for e in embeddings\n",
    "    ]\n",
    "    save_embeddings_json(vector_store_format, \"vector_store_ready.json\")\n",
    "    print(\"Vector Store Format Example (first item):\")\n",
    "    print(json.dumps(vector_store_format[0], indent=2)[:400] + \"...\")\n",
    "    return vector_store_format\n",
    "\n",
    "def example_6(adapter: EmbeddingAdapter):\n",
    "    \"\"\"Real-world PDF processing flow\n",
    "    (In this environment we do not download a PDF; this function demonstrates the flow only.)\n",
    "    \"\"\"\n",
    "    print(\"\\nReal-World PDF Processing Workflow (demo):\")\n",
    "    print(\"This example requires local PDFs or internet access to download a PDF.\")\n",
    "    # Example flow (pseudocode):\n",
    "    # 1) Load PDF with a PDF loader\n",
    "    # 2) Split into chunks with a text splitter\n",
    "    # 3) Generate embeddings for each chunk\n",
    "    # 4) Save to disk\n",
    "    print(\"Use your own PDF loader and RecursiveCharacterTextSplitter equivalent in Python.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f4759fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_examples():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"RAG from Scratch - Generate Embeddings (Python)\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    print(\"Prerequisites:\")\n",
    "    print(\" • Model adapter (dummy by default)\")\n",
    "    print(\" • Python environment with numpy installed\\n\")\n",
    "\n",
    "    adapter = initializeEmbeddingModel(use_dummy=False, dim=384)\n",
    "\n",
    "    try:\n",
    "        print(\"Example 1: Batch Embedding Generation\")\n",
    "        example_1(adapter)\n",
    "\n",
    "        print(\"\\nExample 2: Save and Load Embeddings\")\n",
    "        example_2(adapter)\n",
    "\n",
    "        print(\"\\nExample 3: Incremental Updates\")\n",
    "        example_3(adapter)\n",
    "\n",
    "        print(\"\\nExample 4: Storage Format Comparison\")\n",
    "        example_4(adapter)\n",
    "\n",
    "        print(\"\\nExample 5: Preparing for Vector Stores\")\n",
    "        example_5(adapter)\n",
    "\n",
    "        print(\"\\nExample 6: Real-World PDF Processing (demo)\")\n",
    "        example_6(adapter)\n",
    "\n",
    "        print(\"\\n✅ All examples completed successfully!\")\n",
    "        print(\"Key Takeaways:\")\n",
    "        print(\" • Generate embeddings in batches for efficiency\")\n",
    "        print(\" • Always save embeddings to avoid re-computation\")\n",
    "        print(\" • Use incremental updates for new documents\")\n",
    "        print(\" • Structure data properly for vector stores\\n\")\n",
    "    except Exception as e:\n",
    "        print(\"\\n❌ Error:\", str(e))\n",
    "        print(\"Make sure your environment has numpy and optional adapters if used.\")\n",
    "        print(\"If using a real model, ensure MODEL_PATH exists and your adapter is implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "abaf05dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RAG from Scratch - Generate Embeddings (Python)\n",
      "================================================================================\n",
      "\n",
      "Prerequisites:\n",
      " • Model adapter (dummy by default)\n",
      " • Python environment with numpy installed\n",
      "\n",
      "Loading SentenceTransformer model: all-MiniLM-L6-v2\n",
      "✓ Model loaded successfully\n",
      "Example 1: Batch Embedding Generation\n",
      "Loading embedding model (adapter)...\n",
      "Total Documents: 100\n",
      "\n",
      "Generating embeddings:\n",
      "Progress: 100/100\n",
      "✓ Completed in 0.34s\n",
      "Total Embeddings: 100, Average Time: 3.39ms per document, Throughput: 295.20 docs/sec\n",
      "\n",
      "Example 2: Save and Load Embeddings\n",
      "\n",
      "Phase 1: Generate and Save\n",
      "✓ Generated 50 embeddings in 0.15s\n",
      "✓ Saved to c:\\Projects\\rag-from-scratch\\embedding\\embeddings.json (size: 0.58 MB)\n",
      "\n",
      "Phase 2: Load from Disk\n",
      "✓ Loaded 50 embeddings in 20ms\n",
      "\n",
      "Example 3: Incremental Updates\n",
      "\n",
      "Phase 1: Initial Batch\n",
      "✓ Generated and saved 30 embeddings\n",
      "\n",
      "Phase 2: Add New Documents\n",
      "\n",
      "Attempting to process 25 documents:\n",
      "  - 20 new documents\n",
      "  - 5 duplicates (should skip)\n",
      "Existing embeddings: 30\n",
      "New documents to embed: 20\n",
      "Skipped (already embedded): 5\n",
      "Embedding: 20/20\n",
      "\n",
      "Results:\n",
      " Total Embeddings: 50\n",
      " Update Time: 0.10s\n",
      " New Embeddings: 20\n",
      " Skipped: 5\n",
      "\n",
      "Example 4: Storage Format Comparison\n",
      "\n",
      "Generating embeddings for format comparison...\n",
      "\n",
      "Saving formats:\n",
      "✓ JSON: 1.17 MB\n",
      "\n",
      "Load Time Comparison:\n",
      "JSON: 27ms\n",
      "\n",
      "Example 5: Preparing for Vector Stores\n",
      "\n",
      "Simulating real document processing (chunks)...\n",
      "\n",
      "❌ Error: 'embedding'\n",
      "Make sure your environment has numpy and optional adapters if used.\n",
      "If using a real model, ensure MODEL_PATH exists and your adapter is implemented.\n"
     ]
    }
   ],
   "source": [
    "run_all_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b5da67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
